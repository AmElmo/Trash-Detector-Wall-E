{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jG4maXUgAf9"
      },
      "source": [
        "# **Roadmap**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxH_VmP1gOMc"
      },
      "source": [
        "1. Install the TensorFlow Object Detection API\n",
        "2. Setup folder structure\n",
        "3. Generate the TFRecord files required for training\n",
        "4. Edit the model pipeline config file and download the pre-trained model checkpoint\n",
        "5. Train and evaluate the model\n",
        "\n",
        "⚠️ This notebook is meant to be run in Google Colab for training in order to use GPU capacity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nTZwdPIkgDhC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: nvidia-smi\n"
          ]
        }
      ],
      "source": [
        "# Check GPU setup\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABxZbnKngnQQ",
        "outputId": "0078f0d0-c90b-4787-b68b-42cd97b1b7fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "# Check RAM setup\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIzxfIMHg34x"
      },
      "source": [
        "# **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNjiARb_g2J0",
        "outputId": "364514a9-5ecb-464f-cff5-5461df93f42f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import \n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L37Fm-cMhBjP"
      },
      "source": [
        "# 1. Create customTF2, training and data folders in your google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RzMtcv3h7On"
      },
      "source": [
        "Create a folder named ***customTF2***.\n",
        "\n",
        "Create another folder named ***training*** inside the ***customTF2*** folder\n",
        "(***training*** folder is where the checkpoints will be saved during training)\n",
        "\n",
        "Create another folder named ***data*** inside the ***customTF2*** folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Mount drive and link your folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Clone the tensorflow models git repository & Install TensorFlow Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clone the tensorflow models on the colab cloud vm\n",
        "!git clone --q https://github.com/tensorflow/models.git\n",
        "\n",
        "#navigate to /models/research folder to compile protos\n",
        "%cd models/research\n",
        "\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing the model builder\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Train / Test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use the following repy and script (https://github.com/akarazniewicz/cocosplit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Command to split 80%\n",
        "\n",
        "⬛️ python cocosplit.py --having-annotations --multi-class -s 0.8 '/Users/julienberthomier/code/AmElmo/Main_Projects/Trash Detector (Wall-E)/data/Final_Dataset/final_annotations_coco_V6.json' '/Users/julienberthomier/code/AmElmo/Main_Projects/Trash Detector (Wall-E)/data/Final_Dataset/train.json' '/Users/julienberthomier/code/AmElmo/Main_Projects/Trash Detector (Wall-E)/data/Final_Dataset/test.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Convert Train & Test to TFRecord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We use the fiftyone library for this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('shims')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "b566ac71cdfc16267265dee2636b7f737530ec6a03a2d34aeaa4aaf93d5ca50f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
